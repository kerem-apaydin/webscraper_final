import json
import time
from scraper import collect_all_product_links
from product_parser import parse_product_detail

def main():
    start_url = input("ğŸ”— BaÅŸlangÄ±Ã§ linkini girin: ").strip()

    print("[i] ÃœrÃ¼n linkleri toplanÄ±yor...")
    product_links = collect_all_product_links(start_url)
    print(f"[âœ“] {len(product_links)} Ã¼rÃ¼n linki bulundu.\n")

    all_products = []
    for i, link in enumerate(product_links, 1):
        print(f"[{i}/{len(product_links)}] {link} iÅŸleniyor...")
        data = parse_product_detail(link)
        if data:
            all_products.append(data)
        time.sleep(0.7)

    with open("output.json", "w", encoding="utf-8") as f:
        json.dump(all_products, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… TÃ¼m veriler output.json dosyasÄ±na kaydedildi ({len(all_products)} Ã¼rÃ¼n).")

if __name__ == "__main__":
    main()
